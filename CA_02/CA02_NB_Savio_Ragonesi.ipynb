{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "# CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "# IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "The code bellow imports all the packages and libraries we will need to execute our code properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4p_DvtT7sOIr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os # for file operations and OS interaction\n",
    "import numpy as np # for numerical operations\n",
    "from collections import Counter # for counting the number of instances of each class\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "from sklearn.naive_bayes import GaussianNB # for Gaussian Naive Bayes\n",
    "from sklearn.metrics import accuracy_score # for accuracy calculation\n",
    "# from sklearn.metrics import confusion_matrix # did not use it\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into training and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "The following code has a fucntion that processes/reads emails, tokenizes the words,removes non-alphabetic and single-character words, and returns a list of the most common 3000 words, and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jjKF0nIMwz8_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function that reads the data from the files and create a dictionary\n",
    "def make_Dictionary(root_dir):\n",
    "  all_words = [] # list that stores all the words in the emails\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] # list to store the file paths for all the emails\n",
    "  for mail in emails:\n",
    "    with open(mail) as m:  # reads  email\n",
    "      for line in m:       # iterates through each line in the email\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "  dictionary = Counter(all_words) # the frequency of each word is stored in a dictionary that contains all split words from all emails\n",
    "  list_to_remove = list(dictionary) # creates a list that stores all the words that are to be removed\n",
    "\n",
    "  for item in list_to_remove:\n",
    "    if item.isalpha() == False: # uses boolean to check if the word is alphabetical\n",
    "      del dictionary[item] # if not, the word is removed from the dictionary\n",
    "    elif len(item) == 1: # checks if the word is a single character\n",
    "      del dictionary[item] # the word is removed from the dictionary if len is smaller than 1\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary #creates a dictionary with the 3000 most common words\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "Creating a function that exctracts features from the emails, and labels emails as non-spam 0 or spam 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dmVW5xNlyOFc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function to extract features from the emails\n",
    "def extract_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] # list for file paths of all emails\n",
    "  features_matrix = np.zeros((len(files),3000)) # creating a feature matrix with 3000 coulmns using an array of zeros\n",
    "  train_labels = np.zeros(len(files)) # numpy array with all the zeros, that are our emails\n",
    "  count = 1; # counter for spam emails\n",
    "  docID = 0; # tracks the email ID/row number\n",
    "  for fil in files: # iterates through all the emails\n",
    "    with open(fil) as fi:\n",
    "      for i, line in enumerate(fi): \n",
    "        if i ==2: \n",
    "          words = line.split() # splits the line into words\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            for i, d in enumerate(dictionary): # iterates through the dictionary\n",
    "              if d[0] == word:\n",
    "                wordID = i \n",
    "                features_matrix[docID,wordID] = words.count(word) # counts the number of times a word appears in an email\n",
    "      train_labels[docID] = 0;\n",
    "      filepathTokens = fil.split('\\\\')  # MUST CHANGE BACKSLASHES TO FORWARD SLASHES if you are on a Windows, CHECK README!!!\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"): # checks if the email is spam, start with spmsg, if yes, the label is set to 1\n",
    "        train_labels[docID] = 1; # sets the label to 1\n",
    "        count = count + 1 # adds to the counter\n",
    "      docID = docID + 1  \n",
    "  return features_matrix, train_labels # returns the feature matrix and the labels        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the training data and testing data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zoq-rE7Mx0pp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "# for example: TRAIN_DIR = '../../train-mails'\n",
    "#              TEST_DIR = '../../test-mails'\n",
    "TRAIN_DIR = r\"C:\\Users\\savio\\OneDrive\\Desktop\\Data\\train-mails\" # Changed from original code\n",
    "TEST_DIR = r\"C:\\Users\\savio\\OneDrive\\Desktop\\Data\\test-mails\"   # Changed from original code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and processing all the emails from the folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I printed ( test_features_matrix, test_labels, features_matrix, labels) to verify the functionality of the function since my model was consistently achieving 100% accuracy, which was undesirable. Examining the output, which consisted solely of zeros, revealed that tokenization was not functioning correctly. This observation led me to discover that the original code utilized a Linux path, while I was working on a Windows system. To address this, I modified the path, similar to how I adjusted it when importing the emails above, to my local path, resolving the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print(\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
    "#print( test_features_matrix, test_labels, features_matrix, labels) # Used to fix error check markdown above for clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Training our Gaussian Naive Bayes classifier model and checking its accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naibe Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels .....\n",
      "Testing completed\n",
      "Accuracy of the model is:  0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
    "# train model with Gaussian Naive Bayes\n",
    "email_spam_model = GaussianNB()\n",
    "train = email_spam_model.fit(features_matrix, labels)\n",
    "print(\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
    "print(\"Training completed\")\n",
    "\n",
    "# predicting useing the test \n",
    "test = email_spam_model.predict(test_features_matrix)\n",
    "print(\"testing trained model to predict Test Data labels .....\")\n",
    "print(\"Testing completed\")\n",
    "\n",
    "# Verifying the accuracy of the model\n",
    "accuracy = accuracy_score(test_labels, test)    \n",
    "print(\"Accuracy of the model is: \", accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
